# Story E1.7 — PostgreSQL Statistics Scheduler

## Status
Draft

## Description

Schedule automatic PostgreSQL table statistics refresh (`ANALYZE`) to run daily. This optimizes the query planner by providing accurate table statistics (row counts, data distribution). Currently, statistics are stale, causing the query planner to generate suboptimal execution plans, contributing to high query latency.

**Problem**: PostgreSQL query planner relies on accurate table statistics to choose optimal query execution plans. Without current statistics, planner makes poor choices (e.g., wrong index usage, bad join order). Result: degraded query performance, especially as table sizes change.

**Solution**: Schedule `ANALYZE` job to run daily (off-peak hours, e.g., 2 AM). This refreshes statistics for all tables, allowing query planner to make optimal decisions. Implementation using:
- Option A: `pg_cron` extension (managed in PostgreSQL)
- Option B: Cron + script (external scheduling)

**Impact**: Improve query plan quality, reduce latency, enable query planner to adapt to data changes, supports Phase 2 optimization work.

## Acceptance Criteria

- [ ] Given PostgreSQL `ANALYZE` scheduled, when job runs daily, then no errors in logs
- [ ] Given scheduled statistics refresh, when running queries, then execution plans use current statistics (verified via EXPLAIN)
- [ ] Given query performance, before and after scheduling, then average query latency improves (target: 10% improvement)
- [ ] Given job scheduling, when checking pg_cron or cron history, then ANALYZE runs consistently daily
- [ ] Given statistics refresh, when monitoring job runtime, then completes in <5 minutes (doesn't impact performance)
- [ ] Given configuration, when documented, then team knows when and why ANALYZE runs
- [ ] Given job execution, when logs reviewed, then zero failed runs in 1-week monitoring period

## Scope

### IN (Included)
✅ Schedule `ANALYZE` job to run daily (2 AM recommended)
✅ Use pg_cron extension (preferred) or cron + script
✅ Verify job runs without errors
✅ Monitor job execution time (<5 minutes)
✅ Document configuration and rationale
✅ Create runbook for manual ANALYZE if needed
✅ Performance verification (before/after latency)

### OUT (Not Included)
❌ Full VACUUM jobs (maintenance beyond scope)
❌ Custom statistics collection
❌ Query planner tuning (separate effort)
❌ Real-time statistics updates

## Complexity
**1** — Simple, straightforward database maintenance task, low risk, minimal code changes

## Risks

**Risk: ANALYZE Runs During Business Hours, Impacts Users**
- Mitigation: Schedule during off-peak (2 AM)
- Mitigation: Monitor job runtime, adjust if needed
- Mitigation: Can disable temporarily if issues arise

**Risk: Statistics Become Stale If Job Fails**
- Mitigation: Monitoring and alerting on job failure
- Mitigation: Manual ANALYZE runbook for on-call team
- Mitigation: Weekly status checks

**Risk: Query Plans Change Significantly After Statistics Update**
- Mitigation: Expected and desirable (better plans)
- Mitigation: Monitor for unexpected slowdowns post-update
- Mitigation: Quick rollback possible (re-ANALYZE with old stats)

## Effort Estimate

| Task | Time | Owner |
|------|------|-------|
| Research pg_cron vs. cron+script | 2-4 hours | Backend |
| Implement pg_cron extension setup | 2-4 hours | Backend |
| Schedule ANALYZE job | 1-2 hours | Backend |
| Verify job execution | 2-4 hours | Backend/QA |
| Performance measurement (before/after) | 2-4 hours | Backend |
| Documentation | 2 hours | Backend |
| **Total** | **1 day** | Backend |

## File List
- `backend/alembic/versions/schedule_analyze_job.py` (NEW - migration to set up pg_cron)
- `backend/scripts/analyze_tables.sh` (NEW - fallback script if using cron)
- `docs/RUNBOOK-PostgreSQL-Maintenance.md` (NEW - operational documentation)
- `backend/tests/test_statistics_job.py` (NEW - verification test)

## Dev Notes (updated by @dev)
- [ ] Decide: pg_cron extension vs. cron + script
- [ ] Set up pg_cron extension (if chosen)
- [ ] Create ANALYZE job scheduled for 2 AM
- [ ] Test job runs successfully
- [ ] Monitor job execution time (target: <5 minutes)
- [ ] Verify statistics updated (check last_analyze timestamps)
- [ ] Measure query latency before/after job runs
- [ ] Document configuration in runbook
- [ ] Set up monitoring/alerting for job failure
- [ ] Create manual ANALYZE procedure for emergencies
- [ ] 1-week monitoring to verify stability

## QA Results (filled by @qa)
Verdict: PENDING

---

**Epic**: E1 — Phase 1: Quick Wins
**Priority**: P0 (Critical)
**Type**: Database Maintenance/Optimization
**Effort**: 1 day
**Team**: Backend Developer(s)
